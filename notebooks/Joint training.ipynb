{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import copy\n",
    "import json\n",
    "import time\n",
    "import shutil\n",
    "import time\n",
    "\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "from torch import optim\n",
    "from torch import nn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# TODO: Fix sibling directory imports\n",
    "cwd = os.path.dirname(os.getcwd())\n",
    "sys.path.append(os.path.join(cwd, '.'))\n",
    "\n",
    "from src.datautils.sandia import SandiaDataProvider\n",
    "from src.utils import show_batch_of_images\n",
    "from src.models import mlp_net as mlp\n",
    "from src.reasoning_agents import FFNReasoningAgent, RNN_RA\n",
    "from src.classifiers import PairwiseClassifier\n",
    "from src.utils import show_batch_of_images, dict_of_lists_to_list_of_dicts\n",
    "from src.ra_training import train_reasoning_agent, train_iteration\n",
    "from src.autoencoders import Conv2DAutoencoder, PCAAutoencoder, FeedforwardAutoencoder\n",
    "from src.utiq import UTIQ\n",
    "\n",
    "import src\n",
    "from src import train_test, e2e_training\n",
    "import importlib\n",
    "importlib.reload(src.utils)\n",
    "importlib.reload(src.train_test);\n",
    "importlib.reload(src.e2e_training);\n",
    "from src.train_test import train, test\n",
    "from src.e2e_training import train_e2e"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run from root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/media/yasen/storage/studies/uoe/mlp/sem2/mlp-03/src\n"
     ]
    }
   ],
   "source": [
    "%cd ../src"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparams = {\n",
    "    'img_size': [28],\n",
    "    'encoding_size': [50, 100, 200, 300],\n",
    "\n",
    "    'ae_type': ['ff'],\n",
    "    'ae_hidden_sizes': [[400], [400, 300], [300, 200], [200, 100]],\n",
    "\n",
    "    'ra_type': ['ff'],\n",
    "    'ra_hidden_size': [50, 100, 200],\n",
    "    'ra_num_layers': [1, 2],\n",
    "    'ra_nonlinearity': ['relu'],\n",
    "    'ra_network_type': ['vanilla'],\n",
    "\n",
    "    'clf_type': ['pw'],\n",
    "    'clf_hidden_sizes': [[100], [200, 100], [50], [100, 50], [50, 30], [80, 50, 10]],\n",
    "    'clf_nonlinearity': ['relu'],\n",
    "\n",
    "    'learning_rate': [0.01, 0.05, 0.1, 0.2],\n",
    "    'momentum': [0.1, 0.5, 0.9],\n",
    "    'weight_decay': [0, 0.05],\n",
    "    'num_epochs': [80],\n",
    "    'epoch_patience': [15],\n",
    "    'batch_size': [8, 16, 32, 64]\n",
    "}\n",
    "\n",
    "hyperparams = dict_of_lists_to_list_of_dicts(hyperparams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparams = {\n",
    "    'img_size': [28],\n",
    "    'encoding_size': [50],\n",
    "\n",
    "    'ae_type': ['identity'],\n",
    "    'ae_hidden_sizes': [[400]],\n",
    "    'ae_pretrain': [False],\n",
    "    'ae_freeze': [False],\n",
    "\n",
    "    'ra_type': ['ff'],\n",
    "    'ra_hidden_size': [100],\n",
    "    'ra_num_layers': [2],\n",
    "    'ra_nonlinearity': ['relu'],\n",
    "    'ra_network_type': ['vanilla'],\n",
    "    'ra_use_batchnorm': [False],\n",
    "\n",
    "    'clf_type': ['lse'],\n",
    "    'clf_hidden_sizes': [[80, 40], [100]],\n",
    "    'clf_nonlinearity': ['relu'],\n",
    "    'clf_use_batchnorm': [False],\n",
    "    \n",
    "    'learning_rate': [0.05],\n",
    "    'momentum': [0.5],\n",
    "    'weight_decay': [0.05],\n",
    "    'num_epochs': [50],\n",
    "    'epoch_patience': [10],\n",
    "    'batch_size': [64]\n",
    "}\n",
    "\n",
    "hyperparams = dict_of_lists_to_list_of_dicts(hyperparams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 out of 2:\n",
      "(<class 'ValueError'>, ValueError('too many values to unpack (expected 2)',), <traceback object at 0x7f9876901cc8>)\n",
      "2 out of 2:\n",
      "(<class 'ValueError'>, ValueError('too many values to unpack (expected 2)',), <traceback object at 0x7f98769b14c8>)\n"
     ]
    }
   ],
   "source": [
    "use_cuda = True\n",
    "plot = True\n",
    "for res in train_e2e(hyperparams, use_cuda=use_cuda, verbose=True, plot=plot):\n",
    "    pass"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyTorch(display)",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
