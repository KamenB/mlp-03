{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import copy\n",
    "import json\n",
    "import time\n",
    "import shutil\n",
    "import time\n",
    "\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "from torch import optim\n",
    "from torch import nn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# TODO: Fix sibling directory imports\n",
    "cwd = os.path.dirname(os.getcwd())\n",
    "sys.path.append(os.path.join(cwd, '.'))\n",
    "\n",
    "from src.datautils.sandia import SandiaDataProvider\n",
    "from src.utils import show_batch_of_images\n",
    "from src.models import mlp_net as mlp\n",
    "from src.reasoning_agents import FFNReasoningAgent, RNN_RA\n",
    "from src.classifiers import PairwiseClassifier\n",
    "from src.utils import show_batch_of_images, dict_of_lists_to_list_of_dicts\n",
    "from src.ra_training import train_reasoning_agent, train_iteration\n",
    "from src.autoencoders import Conv2DAutoencoder, PCAAutoencoder, FeedforwardAutoencoder\n",
    "from src.utiq import UTIQ\n",
    "\n",
    "import src\n",
    "from src import train_test, e2e_training\n",
    "import importlib\n",
    "importlib.reload(src.utils)\n",
    "importlib.reload(src.train_test);\n",
    "importlib.reload(src.e2e_training);\n",
    "from src.train_test import train, test\n",
    "from src.e2e_training import train_e2e"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run from root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/miro/AI/mlp2/mlp-03/src\n"
     ]
    }
   ],
   "source": [
    "%cd ../src"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparams = {\n",
    "    'img_size': [28],\n",
    "    'encoding_size': [50, 100, 200, 300],\n",
    "\n",
    "    'ae_type': ['ff'],\n",
    "    'ae_hidden_sizes': [[400], [400, 300], [300, 200], [200, 100]],\n",
    "\n",
    "    'ra_type': ['ff'],\n",
    "    'ra_hidden_size': [50, 100, 200],\n",
    "    'ra_num_layers': [1, 2],\n",
    "    'ra_nonlinearity': ['relu'],\n",
    "    'ra_network_type': ['vanilla'],\n",
    "\n",
    "    'clf_type': ['pw'],\n",
    "    'clf_hidden_sizes': [[100], [200, 100], [50], [100, 50], [50, 30], [80, 50, 10]],\n",
    "    'clf_nonlinearity': ['relu'],\n",
    "\n",
    "    'learning_rate': [0.01, 0.05, 0.1, 0.2],\n",
    "    'momentum': [0.1, 0.5, 0.9],\n",
    "    'weight_decay': [0, 0.05],\n",
    "    'num_epochs': [80],\n",
    "    'epoch_patience': [15],\n",
    "    'batch_size': [8, 16, 32, 64]\n",
    "}\n",
    "\n",
    "hyperparams = dict_of_lists_to_list_of_dicts(hyperparams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparams = {\n",
    "    'img_size': [28],\n",
    "    'encoding_size': [50],\n",
    "\n",
    "    'ae_type': ['identity'],\n",
    "    'ae_hidden_sizes': [[400]],\n",
    "    'ae_pretrain': [False],\n",
    "    'ae_freeze': [False],\n",
    "\n",
    "    'ra_type': ['ff'],\n",
    "    'ra_hidden_size': [100],\n",
    "    'ra_num_layers': [2],\n",
    "    'ra_nonlinearity': ['relu'],\n",
    "    'ra_network_type': ['vanilla'],\n",
    "    'ra_use_batchnorm': [False],\n",
    "\n",
    "    'clf_type': ['lse'],\n",
    "    'clf_hidden_sizes': [[80, 40], [100]],\n",
    "    'clf_nonlinearity': ['relu'],\n",
    "    'clf_use_batchnorm': [False],\n",
    "    \n",
    "    'learning_rate': [0.05],\n",
    "    'momentum': [0.5],\n",
    "    'weight_decay': [0.05],\n",
    "    'num_epochs': [50],\n",
    "    'epoch_patience': [10],\n",
    "    'batch_size': [64]\n",
    "}\n",
    "\n",
    "hyperparams = dict_of_lists_to_list_of_dicts(hyperparams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 out of 2:\n"
     ]
    },
    {
     "ename": "UnboundLocalError",
     "evalue": "local variable 'autoencoder' referenced before assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-26aec9a692c2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mplot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mcount\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mres\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_e2e\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhyperparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_cuda\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_cuda\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplot\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0;34m[\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mcount\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/AI/mlp2/mlp-03/./src/e2e_training.py\u001b[0m in \u001b[0;36mtrain_e2e\u001b[0;34m(hyperparams, use_cuda, verbose, plot)\u001b[0m\n\u001b[1;32m    103\u001b[0m             \u001b[0mreasoning_agent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 105\u001b[0;31m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mUTIQ\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mautoencoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreasoning_agent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_classifier\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mnot\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mclassifier\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0muse_cuda\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mUnboundLocalError\u001b[0m: local variable 'autoencoder' referenced before assignment"
     ]
    }
   ],
   "source": [
    "# %debug\n",
    "use_cuda = False\n",
    "plot = True\n",
    "count = 0\n",
    "models = []\n",
    "for res in train_e2e(hyperparams, use_cuda=use_cuda, verbose=True, plot=plot):\n",
    "    models.append(res[1])\n",
    "    count += 1\n",
    "    print(count)\n",
    "    pass\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import src\n",
    "import importlib\n",
    "importlib.reload(src.utils)\n",
    "importlib.reload(src.train_test)\n",
    "from src.utils import show_matrix\n",
    "from src.utils import make_vars\n",
    "from src.utils import show_grid_of_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models[0] #can chnage that to get diff models\n",
    "# Load question and answer vectors\n",
    "\n",
    "# val_batch_size = val_data.size() \n",
    "#TODO get from model\n",
    "val_batch_size = 8\n",
    "\n",
    "val_loader = val_data.get_batch_iterator(val_batch_size, transpose_inputs=True, separate_inputs=True)\n",
    "\n",
    "(q_vectors, a_vectors), labels = next(val_loader)\n",
    "q_vectors, a_vectors, labels = make_vars([q_vectors, a_vectors, labels], ['float', 'float', 'long'], use_cuda=use_cuda)\n",
    "logits, latent_prediction, decoded_q_vectors, decoded_a_vectors, latent_a_vectors = model(q_vectors, a_vectors)\n",
    "\n",
    "targets = a_vectors\n",
    "\n",
    "indices = torch.from_numpy(np.arange(val_batch_size)).long()\n",
    "if use_cuda:\n",
    "    indices = indices.cuda()\n",
    "targets = targets[indices, labels.data].squeeze()\n",
    "####################\n",
    "sq_err = (latent_a_vectors - latent_prediction) ** 2\n",
    "tot_sq_err = sq_err.sum(2)\n",
    "_, pred_var = torch.min(tot_sq_err, 1)\n",
    "\n",
    "##################\n",
    "# When PCA\n",
    "decoded_prediction = model.autoencoder.decoder(latent_prediction.view(-1, latent_size)).squeeze().view(val_batch_size, 28, 28)\n",
    "#################\n",
    "# When differentiable Conv AE\n",
    "decoded_prediction = model.autoencoder.decoder(latent_prediction.view(-1, latent_size, 1, 1)).squeeze()\n",
    "#########################\n",
    "# When differentiable Linear AE\n",
    "decoded_prediction = model.autoencoder.decoder(latent_prediction.view(-1, latent_size)).squeeze().view(val_batch_size, 28, 28)\n",
    "######################\n",
    "\n",
    "### Show as part of matrix\n",
    "############\n",
    "show_matrix(q_vectors, targets, decoded_q_vectors, decoded_prediction, cmap='gray')\n",
    "######################\n",
    "### Compare with available answers\n",
    "a_vectors_np = a_vectors.cpu().data.numpy()\n",
    "decoded_prediction_np = decoded_prediction.cpu().data.numpy()\n",
    "######################\n",
    "pred, labels\n",
    "####################\n",
    "\n",
    "for i in range(val_batch_size):\n",
    "    show_grid_of_images(np.concatenate([a_vectors_np[i], decoded_prediction_np[i:i+1]]), img_size=(16, 1), grid_size=(1, 9), label=labels[i].cpu().data.numpy(), pred=pred_var[i].cpu().data.numpy(), cmap='gray')\n",
    "###\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
